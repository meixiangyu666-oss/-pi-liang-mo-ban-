import streamlit as st
import pandas as pd
from collections import defaultdict
import sys
import re
import io
from datetime import datetime
import tempfile
import os

# Streamlit App Title and Description
st.title("æ‰¹é‡å¹¿å‘Šä¸Šä¼ æ¨¡ç‰ˆ-ç”Ÿæˆå·¥å…·")
st.markdown("""
### ä»£ç å†…å®¹è¯´æ˜
æ–°ï¼šæ­¤å·¥å…·ç”¨äºä»ä¸Šä¼ çš„ Excel æ–‡ä»¶ï¼ˆé»˜è®¤ sheet: 'å¹¿å‘Šæ¨¡ç‰ˆ'ï¼‰ä¸­æå–å…¨å±€è®¾ç½®ã€æ´»åŠ¨æ•°æ®å’Œå…³é”®è¯ä¿¡æ¯ï¼Œç”Ÿæˆå¹¿å‘Š Header æ–‡ä»¶ã€‚  
**ä¸»è¦åŠŸèƒ½ï¼š**  
- æ”¯æŒï¼ˆå“ç‰Œæ——èˆ°åº—ã€å•†å“é›†ã€å•†å“è¯¦æƒ…é¡µã€SP-å•†å“æ¨å¹¿ï¼‰ä¸»é¢˜çš„åŠ¨æ€åŒºåŸŸæ£€æµ‹å’Œæ•°æ®æå–ã€‚  
- å¤„ç†å¹¿å‘Šæ´»åŠ¨ã€å¹¿å‘Šç»„ã€è§†é¢‘/å•†å“é›†å¹¿å‘Šã€å…³é”®è¯ã€å¦å®šå…³é”®è¯ã€å•†å“å®šå‘ç­‰è¡Œç”Ÿæˆã€‚  
- è‡ªåŠ¨å¡«å……é»˜è®¤å€¼ï¼ˆå¦‚é¢„ç®—ç±»å‹ 'æ¯æ—¥'ã€çŠ¶æ€ 'å·²å¯ç”¨'ï¼‰ã€‚  
- æ£€æµ‹é‡å¤å¦å®šå…³é”®è¯å¹¶æš‚åœç”Ÿæˆï¼ˆæ‰“å°è­¦å‘Šï¼‰ã€‚  
- è¾“å‡ºå¤šSheetå·¥ä½œç°¿ï¼š'å“ç‰Œå¹¿å‘Š' Sheet (SB/SBV) å’Œ 'SP-å•†å“æ¨å¹¿' Sheet (SP)ï¼Œæ¯ä¸ªæœ‰ç‹¬ç«‹åˆ—å¤´ã€‚  

**ä½¿ç”¨æ­¥éª¤ï¼š**  
1. ä¸Šä¼  Excel æ–‡ä»¶ï¼ˆæ–‡ä»¶åä»»æ„ï¼Œéœ€åŒ…å« 'å¹¿å‘Šæ¨¡ç‰ˆ' sheetï¼‰ã€‚  
2. ç‚¹å‡» "ç”Ÿæˆ Header æ–‡ä»¶" æŒ‰é’®ã€‚  
3. ä¸‹è½½ç”Ÿæˆçš„ "header-YYYY-MM-DD HH:MM.xlsx" æ–‡ä»¶ã€‚  

**æ³¨æ„ï¼š**  
- æ–‡ä»¶éœ€ç¬¦åˆè„šæœ¬é¢„æœŸç»“æ„ï¼ˆA åˆ—ä¸»é¢˜è¡Œã€B åˆ—æ´»åŠ¨åç§°ç­‰ï¼‰ã€‚  
- å¦‚é‡é”™è¯¯ï¼ˆå¦‚æœªæ‰¾åˆ°ä¸»é¢˜ï¼‰ï¼Œé¡µé¢å°†æ˜¾ç¤ºæ—¥å¿—ã€‚  
- ç”Ÿæˆæ—¶é—´ç²¾ç¡®åˆ°åˆ†é’Ÿï¼ˆåŸºäºå½“å‰æ—¶é—´ï¼‰ã€‚  
""")

# File Uploader
uploaded_file = st.file_uploader("ä¸Šä¼  Excel æ–‡ä»¶", type=['xlsx', 'xls'])

# Function from the original script (copied and adapted)
def generate_header_for_sbv_brand_store(uploaded_bytes, sheet_name='å¹¿å‘Šæ¨¡ç‰ˆ'):
    # Create a temporary file from bytes
    with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp:
        tmp.write(uploaded_bytes)
        input_file = tmp.name
    
    try:
        # Read the entire file, header=0
        df_survey = pd.read_excel(input_file, sheet_name=sheet_name, header=0)
        st.write(f"æˆåŠŸè¯»å–æ–‡ä»¶ï¼Œæ•°æ®å½¢çŠ¶ï¼š{df_survey.shape}")
        st.write(f"åˆ—ååˆ—è¡¨: {list(df_survey.columns)}")
    except FileNotFoundError:
        st.error(f"é”™è¯¯ï¼šæœªæ‰¾åˆ°æ–‡ä»¶ã€‚è¯·ç¡®ä¿æ–‡ä»¶åŒ…å« '{sheet_name}' sheetã€‚")
        os.unlink(input_file)
        return None
    except Exception as e:
        st.error(f"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™ï¼š{e}")
        os.unlink(input_file)
        return None
    
    #Fill NaN with empty string
    df_survey = df_survey.fillna('')

    # ======== ã€ä¿®æ”¹ 1ï¼šå»ºç«‹å¤–éƒ¨æ˜¾ç¤ºåŒºã€‘ ========
    # åœ¨ expander å¤–é¢å»ºç«‹ä¸€ä¸ªå®¹å™¨ï¼Œä¸“é—¨ç”¨æ¥æ˜¾ç¤ºé”™è¯¯ï¼Œè¿™æ ·ä¸ç”¨ç‚¹å¼€æŠ˜å æ¡†ä¹Ÿèƒ½çœ‹åˆ°
    error_area = st.container()
    # =========================================

    # å¤§ expander åŒ…è£¹æ‰€æœ‰è¯¦ç»†æ—¥å¿—
    with st.expander("æŸ¥çœ‹è¯¦ç»†æ—¥å¿—", expanded=False):
    
        # æ–°åŠ ï¼šåŠ¨æ€åŒºåŸŸæ£€æµ‹å‡½æ•°
        def find_region_start_end(df, target_theme):
            """æ‰«æAåˆ—æ‰¾åˆ°ä¸»é¢˜è¡Œï¼Œè¿”å› (header_row, end_row) (0-basedç´¢å¼•)"""
            theme_row = None
            next_theme_row = None
            for idx, val in enumerate(df.iloc[:, 0]):  # Aåˆ— (index 0)
                if pd.notna(val) and target_theme in str(val).strip():
                    theme_row = idx
                    break
            if theme_row is None:
                st.warning(f"é”™è¯¯ï¼šæœªæ‰¾åˆ°ä¸»é¢˜ '{target_theme}' åœ¨Aåˆ—")
                return None, None
            
            # æ‰¾ä¸‹ä¸€ä¸ªä¸»é¢˜ï¼ˆé¡ºåºï¼šè¯¦æƒ…é¡µ â†’ æ——èˆ°åº— â†’ å•†å“é›† â†’ SPï¼‰
            next_themes = ["SBVè½åœ°é¡µï¼šå“ç‰Œæ——èˆ°åº—", "SBè½åœ°é¡µï¼šå•†å“é›†", "SBVè½åœ°é¡µï¼šå•†å“è¯¦æƒ…é¡µ", "SP-å•†å“æ¨å¹¿"]  # ä»å½“å‰å¼€å§‹æ‰¾ä¸‹ä¸€ä¸ª
            for idx in range(theme_row + 1, len(df)):
                val = str(df.iloc[idx, 0]).strip()
                if any(nt in val for nt in next_themes if nt != target_theme):
                    next_theme_row = idx
                    break
            end_row = next_theme_row - 1 if next_theme_row else len(df) - 1  # åˆ°æ–‡ä»¶æœ«å°¾
            header_row = theme_row + 1  # headeråœ¨ä¸»é¢˜è¡Œä¸‹ä¸€è¡Œ
            st.write(f"æ‰¾åˆ° '{target_theme}' åŒºåŸŸ: ä¸»é¢˜è¡Œ {theme_row+1}, headerè¡Œ {header_row+1}, æ•°æ®åˆ°è¡Œ {end_row+1}")
            return header_row, end_row

        # å…ˆæ‰¾ä¸»é¢˜è¡Œï¼Œç”¨äºé™å…¨å±€è®¾ç½®èŒƒå›´ï¼ˆå–ç¬¬ä¸€ä¸ªä¸»é¢˜å‰ï¼‰
        temp_result = find_region_start_end(df_survey, 'SBVè½åœ°é¡µï¼šå“ç‰Œæ——èˆ°åº—')
        if temp_result[0] is None:
            temp_result = find_region_start_end(df_survey, 'SBè½åœ°é¡µï¼šå•†å“é›†')
        if temp_result[0] is None:
            temp_result = find_region_start_end(df_survey, 'SBVè½åœ°é¡µï¼šå•†å“è¯¦æƒ…é¡µ')
        if temp_result[0] is None:
            temp_result = find_region_start_end(df_survey, 'SP-å•†å“æ¨å¹¿')
        if temp_result[0] is None:
            st.error("æœªæ‰¾åˆ°ä»»ä½•æ”¯æŒçš„ä¸»é¢˜åŒºåŸŸ")
            os.unlink(input_file)
            return None
        global_limit = temp_result[0]  # ç”¨ [0] æ˜¯ header_rowï¼Œå³ä¸»é¢˜å‰

        # Extract global settings: from rows 0-20, column A (0) labels, B (1) values
        global_settings = {}
        for i in range(0, min(20, global_limit)):
            if i >= len(df_survey):
                break
            label = str(df_survey.iloc[i, 0]).strip() if pd.notna(df_survey.iloc[i, 0]) else ''
            value = str(df_survey.iloc[i, 1]).strip() if pd.notna(df_survey.iloc[i, 1]) and len(df_survey.columns) > 1 else ''
            st.write(f"Row {i+1}: label='{label}', value='{value}'")
            
            # Robust matching similar to test SB.py
            if 'å“ç‰Œå®ä½“ç¼–å·' in label or 'ENTITY' in label.upper():
                global_settings['entity_id'] = value
            elif 'å“ç‰Œåç§°' in label:
                global_settings['brand_name'] = value
            elif 'é¢„ç®—ç±»å‹' in label:
                global_settings['budget_type'] = value if value else 'æ¯æ—¥'
            elif 'åˆ›æ„ç´ ææ ‡é¢˜' in label:
                global_settings['creative_title'] = value
            elif 'è½åœ°é¡µ URL' in label:
                global_settings['landing_url'] = value
        
        st.write(f"å…¨å±€è®¾ç½®: {global_settings}")
        
        # ======== ã€ä¿®æ”¹ 1 å¼ºåŠ›è°ƒè¯•ç‰ˆï¼šç²¾å‡†é”å®šâ€œå¹¿å‘Šæ´»åŠ¨åç§°â€åˆ—ã€‘Start ========
        
        # 1. å®šä¹‰å“ªäº›ä¸»é¢˜å¿…é¡»ä¾èµ–å…¨å±€è®¾ç½®
        strict_themes = ['SBè½åœ°é¡µï¼šå•†å“é›†', 'SBVè½åœ°é¡µï¼šå“ç‰Œæ——èˆ°åº—']
        
        # 2. é¢„æ‰«æ
        has_strict_activities = False
        
        for theme in strict_themes:
            h_row, e_row = find_region_start_end(df_survey, theme)
            
            if h_row is not None and e_row > h_row:
                # A. æ‰¾â€œå¹¿å‘Šæ´»åŠ¨åç§°â€è¿™ä¸€åˆ—çš„ç´¢å¼•
                header_vals = df_survey.iloc[h_row]
                target_col_idx = -1
                for idx, val in enumerate(header_vals):
                    if 'å¹¿å‘Šæ´»åŠ¨åç§°' in str(val).strip():
                        target_col_idx = idx
                        break
                
                # B. æ£€æŸ¥è¯¥åˆ—å†…å®¹
                if target_col_idx != -1:
                    # æå–æ•°æ® (ä» headerè¡Œ+1 åˆ° ç»“æŸè¡Œ)
                    col_data = df_survey.iloc[h_row + 1 : e_row + 1, target_col_idx]
                    
                    # --- ğŸ•µï¸ è°ƒè¯•ä¿¡æ¯å¼€å§‹ (å¸®ä½ æ‰¾å‡ºå“ªé‡Œæœ‰éšè—å­—ç¬¦) ---
                    # è½¬æ¢æˆå­—ç¬¦ä¸²å¹¶å»ç©ºæ ¼
                    clean_series = col_data.astype(str).str.strip()
                    # æ‰¾å‡ºéç©ºçš„å€¼ (å¦‚æœä¸ä¸ºç©ºï¼Œè¯´æ˜æœ‰æ•°æ®)
                    non_empty_values = clean_series[clean_series != '']
                    
                    if not non_empty_values.empty:
                        has_strict_activities = True
                        st.error(f"âš ï¸ åœ¨ '{theme}' å‘ç°æœ‰æ•ˆæ´»åŠ¨ï¼")
                        st.write("ğŸ‘‡ ç¨‹åºæ£€æµ‹åˆ°çš„å†…å®¹å¦‚ä¸‹ï¼ˆè¯·æ£€æŸ¥ Excel å¯¹åº”è¡Œï¼‰ï¼š")
                        st.write(non_empty_values) # æŠŠæ£€æµ‹åˆ°çš„â€œå¹½çµæ•°æ®â€æ‰“å°å‡ºæ¥
                        st.write(f"å¯¹åº”è¡Œå·ï¼ˆExcelæ˜¾ç¤ºè¡Œå·éœ€+2ï¼‰ï¼š{non_empty_values.index}")
                        break 
                    else:
                        # åªæœ‰çœŸçš„å…¨æ˜¯ç©ºçš„æ—¶å€™ï¼Œæ‰ä¼šæ˜¾ç¤ºè¿™ä¸ª
                        st.write(f"âœ… '{theme}' åŒºåŸŸçš„â€œå¹¿å‘Šæ´»åŠ¨åç§°â€åˆ—æ˜¯ç©ºçš„ï¼ˆæ£€æµ‹é€šè¿‡ï¼‰ã€‚")
                    # --- ğŸ•µï¸ è°ƒè¯•ä¿¡æ¯ç»“æŸ ---

                else:
                    st.warning(f"âš ï¸ åœ¨ '{theme}' åŒºåŸŸæ²¡æ‰¾åˆ°â€œå¹¿å‘Šæ´»åŠ¨åç§°â€è¿™ä¸€åˆ—ï¼Œè·³è¿‡æ£€æµ‹ã€‚")

        # 3. æ‰§è¡ŒæŠ¥é”™
        if has_strict_activities:
            required_globals = ['creative_title', 'landing_url']
            missing_globals = [k for k in required_globals if not global_settings.get(k)]
            
            if missing_globals:
                error_area.error(f"âŒ ã€ä¸¥é‡é”™è¯¯ã€‘å…¨å±€è®¾ç½®ç¼ºå¤±ï¼")
                error_area.error(f"åŸå› ï¼šä¸Šè¿°è°ƒè¯•ä¿¡æ¯æ˜¾ç¤ºï¼Œ'{theme}' åŒºåŸŸé‡Œç¡®å®æœ‰æ•°æ®ã€‚")
                error_area.error(f"è¯·æ£€æŸ¥æ‰“å°å‡ºæ¥çš„é‚£äº›å•å…ƒæ ¼ï¼Œå¯èƒ½åŒ…å«ç©ºæ ¼æˆ–é—ç•™å­—ç¬¦ã€‚")
                # æš‚åœç”Ÿæˆ
                os.unlink(input_file)
                return None
        else:
            st.info("â„¹ï¸ å…¨å±€è®¾ç½®æ£€æŸ¥é€šè¿‡ï¼šæœªæ£€æµ‹åˆ°éœ€è¦å¿…å¡«ä¿¡æ¯çš„æ´»åŠ¨ã€‚")
            
        # ======== ã€ä¿®æ”¹ 1 å¼ºåŠ›è°ƒè¯•ç‰ˆï¼šç²¾å‡†é”å®šâ€œå¹¿å‘Šæ´»åŠ¨åç§°â€åˆ—ã€‘End ========
        
        # Keyword columns: from header row (iloc[0]), but dynamic like test SB.py
        header_row_full = df_survey.iloc[0].tolist()
        keyword_columns = [col for col in header_row_full if isinstance(col, str) and ('ç²¾å‡†è¯' in col or 'å¹¿æ³›è¯' in col or 'å¦' in col)]
        st.write(f"å…³é”®è¯ç›¸å…³åˆ—: {keyword_columns}")
        
        # Identify keyword categories like in test SB.py
        keyword_categories = set()
        for col in keyword_columns:
            col_lower = str(col).lower()
            if '/' in col_lower:
                parts = col_lower.split('/')
                if len(parts) > 0 and parts[0]:
                    keyword_categories.add(parts[0].strip())
                if len(parts) > 1 and parts[1]:
                    chinese_part = parts[1].split('-')[0].strip() if '-' in parts[1] else parts[1].strip()
                    keyword_categories.add(chinese_part)
            else:
                for suffix in ['ç²¾å‡†è¯', 'å¹¿æ³›è¯', 'ç²¾å‡†', 'å¹¿æ³›']:
                    if col_lower.endswith(suffix):
                        prefix = col_lower[:-len(suffix)].strip()
                        if prefix:
                            keyword_categories.add(prefix)
                            break
        keyword_categories.update(['suzhu', 'å®¿ä¸»', 'host', 'case', 'åŒ…', 'å¯¹æ‰‹', 'tape'])
        st.write(f"è¯†åˆ«åˆ°çš„å…³é”®è¯ç±»åˆ«: {keyword_categories}")
        
        # Negative keywords extraction: map to specific columns like test SB.py
        # Col indices mapping
        col_indices = {
            'W': df_survey.columns.get_loc('å®¿ä¸»ç²¾å‡†-å¦ç²¾å‡†') if 'å®¿ä¸»ç²¾å‡†-å¦ç²¾å‡†' in df_survey.columns else None,
            'X': df_survey.columns.get_loc('å®¿ä¸»ç²¾å‡†-å¦è¯ç»„') if 'å®¿ä¸»ç²¾å‡†-å¦è¯ç»„' in df_survey.columns else None,
            'AA': df_survey.columns.get_loc('å®¿ä¸»å¹¿æ³›-å¦ç²¾å‡†') if 'å®¿ä¸»å¹¿æ³›-å¦ç²¾å‡†' in df_survey.columns else None,
            'AB': df_survey.columns.get_loc('å®¿ä¸»å¹¿æ³›-å¦è¯ç»„') if 'å®¿ä¸»å¹¿æ³›-å¦è¯ç»„' in df_survey.columns else None,
            'Y': df_survey.columns.get_loc('caseç²¾å‡†-å¦ç²¾å‡†') if 'caseç²¾å‡†-å¦ç²¾å‡†' in df_survey.columns else None,
            'Z': df_survey.columns.get_loc('caseç²¾å‡†-å¦è¯ç»„') if 'caseç²¾å‡†-å¦è¯ç»„' in df_survey.columns else None,
            'AC': df_survey.columns.get_loc('caseå¹¿æ³›-å¦ç²¾å‡†') if 'caseå¹¿æ³›-å¦ç²¾å‡†' in df_survey.columns else None,
            'AD': df_survey.columns.get_loc('caseå¹¿æ³›-å¦è¯ç»„') if 'caseå¹¿æ³›-å¦è¯ç»„' in df_survey.columns else None,
        }
        
        # Col names for logging
        col_names_dict = {
            'W': 'å®¿ä¸»ç²¾å‡†-å¦ç²¾å‡†',
            'X': 'å®¿ä¸»ç²¾å‡†-å¦è¯ç»„',
            'AA': 'å®¿ä¸»å¹¿æ³›-å¦ç²¾å‡†',
            'AB': 'å®¿ä¸»å¹¿æ³›-å¦è¯ç»„',
            'Y': 'caseç²¾å‡†-å¦ç²¾å‡†',
            'Z': 'caseç²¾å‡†-å¦è¯ç»„',
            'AC': 'caseå¹¿æ³›-å¦ç²¾å‡†',
            'AD': 'caseå¹¿æ³›-å¦è¯ç»„'
        }
        
        # Extract neg_asin and neg_brand from specific columns
        neg_asin = []
        neg_brand = []
        neg_asin_col = None
        neg_brand_col = None
        for col_idx, col_name in enumerate(df_survey.columns):
            if 'å¦å®šasin' in str(col_name).lower():
                neg_asin_col = col_idx
            elif 'å¦å“ç‰Œ' in str(col_name).lower():
                neg_brand_col = col_idx
        if neg_asin_col is not None:
            neg_asin = [str(x).strip() for x in df_survey.iloc[:, neg_asin_col].dropna() if str(x).strip()]
            neg_asin = list(dict.fromkeys(neg_asin))
        if neg_brand_col is not None:
            neg_brand = [str(int(x)).strip() for x in df_survey.iloc[:, neg_brand_col].dropna() if str(x).strip()]
            neg_brand = list(dict.fromkeys(neg_brand))
        st.write(f"å¦å®šASIN: {neg_asin}")
        st.write(f"å¦å“ç‰Œ: {neg_brand}")
        
        # Output columns for Brand (SB/SBV) - original 27 columns
        output_columns_brand = [
            'äº§å“', 'å®ä½“å±‚çº§', 'æ“ä½œ', 'å¹¿å‘Šæ´»åŠ¨ç¼–å·', 'å¹¿å‘Šç»„ç¼–å·', 'å¹¿å‘Šç¼–å·', 
            'å¹¿å‘Šæ´»åŠ¨åç§°', 'å¹¿å‘Šç»„åç§°', 'å¹¿å‘Šåç§°', 'çŠ¶æ€', 'å“ç‰Œå®ä½“ç¼–å·', 
            'é¢„ç®—ç±»å‹', 'é¢„ç®—', 'å•†å“ä½ç½®', 'ç«ä»·', 'å…³é”®è¯æ–‡æœ¬', 'åŒ¹é…ç±»å‹', 'æ‹“å±•å•†å“æŠ•æ”¾ç¼–å·', 
            'è½åœ°é¡µ URL', 'è½åœ°é¡µç±»å‹', 'å“ç‰Œåç§°', 'åŒæ„ç¿»è¯‘', 'å“ç‰Œå¾½æ ‡ç´ æç¼–å·', 
            'åˆ›æ„ç´ ææ ‡é¢˜', 'åˆ›æ„ç´ æ ASIN', 'è§†é¢‘ç´ æç¼–å·', 'è‡ªå®šä¹‰å›¾ç‰‡', 'è½åœ°é¡µ ASIN'
        ]
        
        # Output columns for SP - based on header-B_US (25 columns)
        output_columns_sp = [
            'äº§å“', 'å®ä½“å±‚çº§', 'æ“ä½œ', 'å¹¿å‘Šæ´»åŠ¨ç¼–å·', 'å¹¿å‘Šç»„ç¼–å·', 'å¹¿å‘Šç»„åˆç¼–å·', 'å¹¿å‘Šç¼–å·', 'å…³é”®è¯ç¼–å·', 
            'å•†å“æŠ•æ”¾ ID', 'å¹¿å‘Šæ´»åŠ¨åç§°', 'å¹¿å‘Šç»„åç§°', 'å¼€å§‹æ—¥æœŸ', 'ç»“æŸæ—¥æœŸ', 'æŠ•æ”¾ç±»å‹', 'çŠ¶æ€', 
            'æ¯æ—¥é¢„ç®—', 'SKU', 'å¹¿å‘Šç»„é»˜è®¤ç«ä»·', 'ç«ä»·', 'å…³é”®è¯æ–‡æœ¬', 'åŒ¹é…ç±»å‹', 'ç«ä»·æ–¹æ¡ˆ', 
            'å¹¿å‘Šä½', 'ç™¾åˆ†æ¯”', 'æ‹“å±•å•†å“æŠ•æ”¾ç¼–å·'
        ]
        
        product_brand = 'å“ç‰Œæ¨å¹¿'
        product_sp = 'å•†å“æ¨å¹¿'
        operation = 'Create'
        status = 'å·²å¯ç”¨'
        
        # Separate rows for brand and SP
        brand_rows = []
        sp_rows = []
        
        default_bid = 0.6
        default_sp_budget = 12  # SP default budget from header-B_US

        # [ä¿®æ”¹ 2] åˆå§‹åŒ–é”™è¯¯æ—¥å¿—åˆ—è¡¨
        validation_errors = []
        
        # æ”¯æŒçš„ä¸»é¢˜åˆ—è¡¨ï¼ˆåŸä»£ç ï¼‰
        targets = ['SBVè½åœ°é¡µï¼šå“ç‰Œæ——èˆ°åº—', 'SBè½åœ°é¡µï¼šå•†å“é›†', 'SBVè½åœ°é¡µï¼šå•†å“è¯¦æƒ…é¡µ', 'SP-å•†å“æ¨å¹¿']
        
        # æ”¯æŒçš„ä¸»é¢˜åˆ—è¡¨ï¼ˆæ·»åŠ SPï¼‰
        targets = ['SBVè½åœ°é¡µï¼šå“ç‰Œæ——èˆ°åº—', 'SBè½åœ°é¡µï¼šå•†å“é›†', 'SBVè½åœ°é¡µï¼šå•†å“è¯¦æƒ…é¡µ', 'SP-å•†å“æ¨å¹¿']
        
        for target_theme in targets:
            header_row, end_row = find_region_start_end(df_survey, target_theme)
            if header_row is None:
                st.warning(f"è·³è¿‡ä¸»é¢˜ '{target_theme}'ï¼šæœªæ‰¾åˆ°åŒºåŸŸ")
                continue

            # è¯»å–headerè¡Œä½œä¸ºåˆ—å
            header_data = pd.read_excel(input_file, sheet_name=sheet_name, skiprows=header_row, nrows=1)
            col_names = header_data.iloc[0].tolist()  # è·å–åˆ—å
            
            # è¯»å–æ•°æ®è¡Œ (ä»headerä¸‹ä¸€è¡Œåˆ°end_row)
            activity_df = pd.DataFrame()
            if end_row > header_row:
                activity_df = pd.read_excel(input_file, sheet_name=sheet_name, skiprows=header_row + 1, nrows=end_row - header_row)
                activity_df.columns = col_names  # è®¾ç½®åˆ—å
                st.write(f"æ´»åŠ¨æ•°æ®å½¢çŠ¶ ({target_theme}): {activity_df.shape}")
                st.write(f"æ´»åŠ¨åˆ—å ({target_theme}): {list(activity_df.columns)}")
            else:
                st.warning(f"æ— æ´»åŠ¨æ•°æ®è¡Œ ({target_theme})")
                continue

            # åŠ å¡«å…… NaN
            activity_df = activity_df.fillna('')

            # ç”¨activity_dfæ„å»ºactivity_rowsåˆ—è¡¨ï¼Œæ ¹æ®ä¸»é¢˜ä¸åŒæå–ä¸åŒ
            activity_rows = []
            if 'SP-å•†å“æ¨å¹¿' in target_theme:
                # SP é€»è¾‘ï¼šåŠ¨æ€æŸ¥æ‰¾åˆ—åç´¢å¼•ï¼Œç±»ä¼¼SBä½†è°ƒæ•´ä¸ºSPå­—æ®µ
                for idx, row in activity_df.iterrows():
                    # åŠ¨æ€è·å–åˆ—ç´¢å¼• for SP
                    campaign_col = None
                    cpc_col = None
                    sku_col = None
                    budget_col = None
                    group_bid_col = None  # æ–°åŠ ï¼šå£°æ˜å˜é‡ï¼Œæ‰¾â€œå¹¿å‘Šç»„é»˜è®¤ç«ä»·â€åˆ—
                    ad_position_col = None  # æ–°å¢ï¼šå¹¿å‘Šä½åˆ—ç´¢å¼•
                    percentage_col = None
                    for col_idx, col_name in enumerate(activity_df.columns):
                        col_str = str(col_name).strip().lower()
                        if 'å¹¿å‘Šæ´»åŠ¨åç§°' in col_str:
                            campaign_col = col_idx
                        elif 'cpc' in col_str:
                            cpc_col = col_idx
                        elif 'sku' in col_str:
                            sku_col = col_idx
                        elif 'é¢„ç®—' in col_str:
                            budget_col = col_idx
                        elif 'å¹¿å‘Šç»„é»˜è®¤ç«ä»·' in col_str:
                            group_bid_col = col_idx
                        elif 'å¹¿å‘Šä½' in col_str:
                            ad_position_col = col_idx
                        elif 'ç™¾åˆ†æ¯”' in col_str:
                            percentage_col = col_idx
                    
                    # æå–å€¼
                    campaign_name = str(row.iloc[campaign_col]).strip() if campaign_col is not None else ''
                    cpc = str(row.iloc[cpc_col]).strip() if cpc_col is not None else ''
                    sku = str(row.iloc[sku_col]).strip() if sku_col is not None else ''
                    budget = str(row.iloc[budget_col]).strip() if budget_col is not None else ''
                    group_bid = str(row.iloc[group_bid_col]).strip() if group_bid_col is not None else ''
                    ad_position = str(row.iloc[ad_position_col]).strip() if ad_position_col is not None else ''
                    percentage = str(int(float(row.iloc[percentage_col]))) if percentage_col is not None and pd.notna(row.iloc[percentage_col]) and row.iloc[percentage_col] != '' else ''
                    
                    if campaign_name:
                        activity = {
                            'campaign_name': campaign_name,
                            'cpc': cpc,
                            'sku': sku,
                            'budget': budget,
                            'group_bid': group_bid,
                            'ad_position': ad_position,
                            'percentage': percentage
                        }
                        activity_rows.append(activity)
                        st.write(f"  SP æ´»åŠ¨: {campaign_name}, CPC={cpc}, é¢„ç®—={budget}, å¹¿å‘Šä½={ad_position}, ç™¾åˆ†æ¯”={percentage}")
            
            else:
                # Brand é€»è¾‘ï¼šåŠ¨æ€æŸ¥æ‰¾åˆ—åç´¢å¼•
                for idx, row in activity_df.iterrows():
                    # åŠ¨æ€è·å–åˆ—ç´¢å¼• for Brand
                    campaign_col = None
                    cpc_col = None
                    budget_col = None # ç¡®ä¿é¢„ç®—åˆ—ä¹Ÿåœ¨
                    asins_cols = [3, 4, 5]
                    video_media_col = None  # æ–°å¢ï¼šåˆå§‹åŒ–è§†é¢‘åª’ä½“åˆ—ç´¢å¼•
                    custom_image_col = None  # æ–°å¢ï¼šåˆå§‹åŒ–è‡ªå®šä¹‰å›¾ç‰‡åˆ—ç´¢å¼•
                    landing_type_col = None
                    for col_idx, col_name in enumerate(activity_df.columns):
                        col_str = str(col_name).strip().lower()
                        if 'å¹¿å‘Šæ´»åŠ¨åç§°' in col_str:
                            campaign_col = col_idx
                        elif 'cpc' in col_str:
                            cpc_col = col_idx
                        elif 'é¢„ç®—' in col_str:
                            budget_col = col_idx
                        elif 'è§†é¢‘åª’ä½“' in col_str and 'ç¼–å·' in col_str:  # æ–°å¢ï¼šåŒ¹é…â€œè§†é¢‘åª’ä½“ç¼–å·â€åˆ—
                            video_media_col = col_idx
                        elif 'è‡ªå®šä¹‰å›¾ç‰‡' in col_str:  # æ–°å¢ï¼šåŒ¹é…â€œè‡ªå®šä¹‰å›¾ç‰‡â€åˆ—
                            custom_image_col = col_idx
                        elif 'è½åœ°é¡µç±»å‹' in col_str: # ã€æ–°å¢ã€‘å¦‚æœåˆ—ååŒ…å«è½åœ°é¡µç±»å‹ï¼Œè®°å½•å®ƒçš„ä½ç½®
                            landing_type_col = col_idx
                    
                    # æå–å€¼
                    campaign_name = str(row.iloc[campaign_col]).strip() if campaign_col is not None else ''
                    cpc = str(row.iloc[cpc_col]).strip() if cpc_col is not None else ''
                    
                    # ã€æ–°å¢ã€‘æå–å½“å‰è¡Œçš„è½åœ°é¡µç±»å‹ã€‚å¦‚æœæ²¡å¡«ï¼Œåˆ™æ ¹æ®å¤§åŒºåŸŸè‡ªåŠ¨è¡¥å…¨
                    row_landing_type = str(row.iloc[landing_type_col]).strip() if landing_type_col is not None else ''

                    asins_list = []
                    for col in asins_cols:  # ç”¨åˆ—è¡¨asins_cols
                        cell_val = str(row.iloc[col]).strip()
                        if cell_val:
                            asins_list.extend([asin.strip() for asin in cell_val.split(',')])  # splité€—å·æ‰©å±•
                    unique_asins = list(dict.fromkeys(asins_list))  # æœ‰åºå»é‡ï¼ˆä¿æŒDâ†’Eâ†’Fé¡ºåºï¼‰
                    asins_str = ', '.join(unique_asins) if unique_asins else ''
                    video_asset = str(row.iloc[video_media_col]).strip() if video_media_col is not None else ''  # æ–°å¢ï¼šæå–è§†é¢‘ç´ æå€¼
                    custom_image = str(row.iloc[custom_image_col]).strip() if custom_image_col is not None else ''  # æ–°å¢ï¼šæå–è‡ªå®šä¹‰å›¾ç‰‡å€¼ï¼ˆè¦†ç›–åŸç¡¬ç¼–ç custom_image = ''ï¼‰
                    print(f"  è‡ªå®šä¹‰å›¾ç‰‡: '{custom_image}' (col={custom_image_col})")
                    # æ–°å¢ï¼šä¸ºå½“å‰è¡Œæå–å“ç‰Œå¾½æ ‡ç´ æç¼–å·
                    logo_asset = ''
                    logo_col_idx = None

                    # ä¼˜å…ˆï¼šæŒ‰åˆ—åæŸ¥æ‰¾ï¼ˆæœ€ç¨³å¥ï¼‰
                    for col_idx, col_name in enumerate(activity_df.columns):
                        if 'å“ç‰Œå¾½æ ‡ç´ æç¼–å·' in str(col_name):
                            logo_col_idx = col_idx
                            break

                    # Fallback åˆ°å›ºå®š J åˆ— (index 9)
                    if logo_col_idx is None:
                        if len(activity_df.columns) > 9:
                            logo_col_idx = 9
                            st.write(f"  æœªæ‰¾åˆ°â€˜å“ç‰Œå¾½æ ‡ç´ æç¼–å·â€™åˆ—åï¼Œä½¿ç”¨å›ºå®šJåˆ—ï¼ˆç¬¬10åˆ—ï¼‰ (æ´»åŠ¨: {campaign_name})")
                        else:
                            st.warning(f"  æ•°æ®åˆ—ä¸è¶³10åˆ—ï¼Œæ— æ³•è¯»å–å“ç‰Œå¾½æ ‡ç´ æç¼–å· (æ´»åŠ¨: {campaign_name})")

                    # ä»å½“å‰è¡Œè¯»å–
                    if logo_col_idx is not None:
                        cell_value = row.iloc[logo_col_idx] if logo_col_idx < len(row) else ''
                        if pd.notna(cell_value):
                            logo_asset = str(cell_value).strip()

                    if campaign_name:
                        activity = {
                            'campaign_name': campaign_name,
                            'cpc': cpc,
                            'asins': asins_str,
                            'budget': str(row.iloc[budget_col]).strip() if budget_col is not None else '12',
                            'video_asset': video_asset,  # æ–°å¢ï¼šä¿å­˜è§†é¢‘
                            'custom_image': custom_image,  # æ–°å¢ï¼šä¿å­˜è‡ªå®šä¹‰å›¾ç‰‡
                            'logo_asset': logo_asset,
                            'landing_type': row_landing_type # ã€æ–°å¢ã€‘ä¿å­˜åˆ°æ´»åŠ¨ä¿¡æ¯é‡Œ
                        }
                        activity_rows.append(activity)
                        st.write(f"  Brand æ´»åŠ¨: {campaign_name}, CPC={cpc}")

            st.write(f"Found {len(activity_rows)} activity rows ({target_theme}): {[r['campaign_name'] for r in activity_rows]}")
            
            
            # Generate rows for this region
            for activity in activity_rows:
                campaign_name = activity['campaign_name']
                st.write(f"å¤„ç†æ´»åŠ¨ ({target_theme}): {campaign_name}")

                # ======== ã€ç¬¬3å¤„æ’å…¥ï¼šå¼€å§‹ã€‘ ========
                # 2. å¿…å¡«é¡¹ä¸ ASIN é€»è¾‘æ£€æŸ¥
                # A. æ£€æŸ¥é€šç”¨å¿…å¡«é¡¹
                if not str(activity.get('cpc', '')).strip():
                    validation_errors.append(f"âŒ æ´»åŠ¨ [{campaign_name}]: ç¼ºå°‘ 'CPC'")
                if not str(activity.get('budget', '')).strip():
                    validation_errors.append(f"âŒ æ´»åŠ¨ [{campaign_name}]: ç¼ºå°‘ 'é¢„ç®—'")

                # B. æ ¹æ®ç±»å‹æ£€æŸ¥ç‰¹å®šå­—æ®µ
                if 'SP-å•†å“æ¨å¹¿' in target_theme:
                    if not str(activity.get('sku', '')).strip():
                        validation_errors.append(f"âŒ æ´»åŠ¨ [{campaign_name}]: ç¼ºå°‘ 'SKU'")
                    if not str(activity.get('group_bid', '')).strip():
                        validation_errors.append(f"âŒ æ´»åŠ¨ [{campaign_name}]: ç¼ºå°‘ 'å¹¿å‘Šç»„é»˜è®¤ç«ä»·'")
                else:
                    # Brand æ£€æŸ¥
                    # 1. è§†é¢‘æ£€æŸ¥ï¼šå¦‚æœæ˜¯è§†é¢‘å¹¿å‘Šï¼Œå¿…é¡»æœ‰è§†é¢‘ ID
                    if 'å“ç‰Œæ——èˆ°åº—' in target_theme or 'å•†å“è¯¦æƒ…é¡µ' in target_theme:
                         if not str(activity.get('video_asset', '')).strip():
                            validation_errors.append(f"âŒ æ´»åŠ¨ [{campaign_name}]: ç¼ºå°‘ 'è§†é¢‘åª’ä½“ç¼–å·'")
                    
                    # 2. Logo æ£€æŸ¥ï¼šã€ä¿®æ”¹è¿™é‡Œã€‘æ’é™¤ "å•†å“è¯¦æƒ…é¡µ"ï¼Œåªæœ‰å…¶ä»–ç±»å‹æ‰æŸ¥ Logo
                    if 'å•†å“è¯¦æƒ…é¡µ' not in target_theme:
                        if not str(activity.get('logo_asset', '')).strip():
                            validation_errors.append(f"âŒ æ´»åŠ¨ [{campaign_name}]: ç¼ºå°‘ 'å“ç‰Œå¾½æ ‡ç´ æç¼–å·'")
                    
                    # 3. è½åœ°é¡µç±»å‹æ£€æŸ¥
                    if not str(activity.get('landing_type', '')).strip():
                        validation_errors.append(f"âŒ æ´»åŠ¨ [{campaign_name}]: ç¼ºå°‘ 'è½åœ°é¡µç±»å‹'")

                    # 4. æ£€æŸ¥åˆ›æ„ç´ æ ASIN (Dã€Eã€F åˆ—)
                    # åªè¦æ˜¯ æ——èˆ°åº—ã€è¯¦æƒ…é¡µã€å•†å“é›† è¿™ä¸‰ç±»ï¼ŒASIN ä¸èƒ½ä¸ºç©º
                    check_asin_themes = ['å“ç‰Œæ——èˆ°åº—', 'å•†å“è¯¦æƒ…é¡µ', 'å•†å“é›†']
                    if any(x in target_theme for x in check_asin_themes):
                        # activity['asins'] æ˜¯ä» D/E/F åˆ—æå–å¹¶åˆå¹¶çš„å­—ç¬¦ä¸²
                        if not str(activity.get('asins', '')).strip():
                            validation_errors.append(f"âŒ æ´»åŠ¨ [{campaign_name}]: ç¼ºå°‘ 'åˆ›æ„ç´ æ ASIN' (è¯·æ£€æŸ¥ Dã€Eã€F åˆ—æ˜¯å¦å¡«å†™)")

                # C. ASIN å®šå‘æ™ºèƒ½æ£€æŸ¥
                temp_name_check = str(campaign_name).lower()
                is_asin_check = any(x in temp_name_check for x in ['asin'])
                
                if is_asin_check:
                    asin_found_check = False
                    for col in df_survey.columns:
                        if str(col).strip() == str(campaign_name):
                            # æ£€æŸ¥è¯¥åˆ—æ˜¯å¦æœ‰å€¼
                            col_idx = df_survey.columns.get_loc(col)
                            vals = [x for x in df_survey.iloc[:, col_idx].dropna() if str(x).strip()]
                            if vals:
                                asin_found_check = True
                            break
                    
                    if not asin_found_check:
                         validation_errors.append(f"âŒ æ´»åŠ¨ [{campaign_name}]: æ˜¯ ASIN æŠ•æ”¾ï¼Œä½†åœ¨è¡¨å¤´æœªæ‰¾åˆ°å¯¹åº”åˆ—æˆ–åˆ—ä¸‹æ— æ•°æ®ï¼")
                # ======== ã€ç¬¬3å¤„æ’å…¥ï¼šç»“æŸã€‘ ========
                
                is_asin = False  # åˆå§‹åŒ–å˜é‡ï¼Œé¿å… UnboundLocalError
                
                if 'SP-å•†å“æ¨å¹¿' in target_theme:
                    # SP-specific generation
                    cpc = float(activity['cpc']) if activity['cpc'] != '' else default_bid
                    budget = float(activity['budget']) if activity['budget'] != '' else default_sp_budget
                    sku = activity.get('sku', 'SKU-1')
                    group_bid = float(activity.get('group_bid', default_bid))
                    
                    campaign_name_normalized = str(campaign_name).lower()
                    
                    # Detect category and match type like test SB.py
                    matched_category = None
                    for cat in keyword_categories:
                        if cat in campaign_name_normalized:
                            matched_category = cat
                            break
                    
                    is_exact = any(x in campaign_name_normalized for x in ['ç²¾å‡†', 'exact', 'sp_exact'])
                    is_broad = any(x in campaign_name_normalized for x in ['å¹¿æ³›', 'broad', 'sp_broad'])
                    is_asin = any(x in campaign_name_normalized for x in ['asin', 'sp_asin'])  # è¦†ç›–èµ‹å€¼
                    match_type = 'ç²¾å‡†' if is_exact else 'å¹¿æ³›' if is_broad else 'ç²¾å‡†'  # Default exact/ç²¾å‡†
                    
                    # Row1: å¹¿å‘Šæ´»åŠ¨
                    row1 = [product_sp, 'å¹¿å‘Šæ´»åŠ¨', operation, campaign_name, '', '', '', '', '', campaign_name, '', '', '', 'æ‰‹åŠ¨', status, 
                            budget, '', '', '', '', '', 'åŠ¨æ€ç«ä»· - ä»…é™ä½', '', '', '']
                    sp_rows.append(row1)
                    
                    # Row2: å¹¿å‘Šç»„
                    row2 = [product_sp, 'å¹¿å‘Šç»„', operation, campaign_name, campaign_name, '', '', '', '', campaign_name, campaign_name, '', '', '', status, 
                            '', '', group_bid, '', '', '', '', '', '', '']
                    sp_rows.append(row2)
                    
                    # Row3: å•†å“å¹¿å‘Š
                    row3 = [product_sp, 'å•†å“å¹¿å‘Š', operation, campaign_name, campaign_name, '', '', '', '', campaign_name, campaign_name, '', '', '', status, 
                            '', sku, '', '', '', '', '', '', '', '']
                    sp_rows.append(row3)
                    
                    if not is_asin:
                        # Keywords: dynamic column selection based on region rules (SP original)
                        keywords = []
                        keyword_col_idx = None
                        col_name = None  # For logging
                        
                        if match_type == 'ç²¾å‡†':
                            if matched_category in ['suzhu', 'å®¿ä¸»', 'host']:
                                col_name = 'suzhu/å®¿ä¸»/host-ç²¾å‡†è¯'
                            elif matched_category in ['case', 'åŒ…']:
                                col_name = 'case/åŒ…-ç²¾å‡†è¯'
                        elif match_type == 'å¹¿æ³›':
                            # SP: original rules
                            if matched_category in ['suzhu', 'å®¿ä¸»', 'host']:
                                col_name = 'suzhu/å®¿ä¸»/host-å¹¿æ³›è¯'  # Måˆ—
                            elif matched_category in ['case', 'åŒ…']:
                                col_name = 'case/åŒ…-å¹¿æ³›è¯'  # Påˆ—
                        
                        if col_name and keyword_col_idx is None:
                            try:
                                keyword_col_idx = df_survey.columns.get_loc(col_name)
                            except KeyError:
                                st.warning(f"åˆ— '{col_name}' æœªæ‰¾åˆ°ï¼Œfallbackåˆ°ç¡¬ç¼–ç ")
                                # Fallback for SP: original indices
                                if 'ç²¾å‡†' in match_type and matched_category in ['suzhu', 'å®¿ä¸»', 'host']:
                                    keyword_col_idx = 11
                                elif 'å¹¿æ³›' in match_type and matched_category in ['suzhu', 'å®¿ä¸»', 'host']:
                                    keyword_col_idx = 12  # M
                                elif 'ç²¾å‡†' in match_type and matched_category in ['case', 'åŒ…']:
                                    keyword_col_idx = 14
                                elif 'å¹¿æ³›' in match_type and matched_category in ['case', 'åŒ…']:
                                    keyword_col_idx = 15  # P
                        
                        if keyword_col_idx is not None and keyword_col_idx < len(df_survey.columns):
                            col_data = [str(kw).strip() for kw in df_survey.iloc[:, keyword_col_idx].dropna() if str(kw).strip()]
                            keywords = list(dict.fromkeys(col_data))
                            col_name = str(df_survey.columns[keyword_col_idx]) if col_name is None else col_name
                            st.write(f"  åŒ¹é…çš„åˆ—: {col_name} (idx={keyword_col_idx})")
                            st.write(f"  å…³é”®è¯æ•°é‡: {len(keywords)} (ç¤ºä¾‹: {keywords[:2] if keywords else 'æ— '})")
                        else:
                            keywords = []
                            st.warning(f"  æ— åŒ¹é…åˆ— for {matched_category} {match_type} in {target_theme}")
                    
                        if keywords:
                            for kw in keywords:
                                row_keyword = [product_sp, 'å…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '', campaign_name, campaign_name, '', '', '', status, 
                                            '', '', '', cpc, kw, match_type, '', '', '', '']
                                sp_rows.append(row_keyword)
                        else:
                            st.warning(f"  æ— å…³é”®è¯æ•°æ®ï¼Œè·³è¿‡ç”Ÿæˆå…³é”®è¯å±‚çº§ (æ´»åŠ¨: {campaign_name})")
                        
                        # Negative keywords: dynamic like test SB.py, with specific column selection
                        if matched_category:
                            # Select columns based on category and type (SP similar to Brand)
                            selected_cols = []
                            if matched_category in ['suzhu', 'å®¿ä¸»', 'host']:
                                if is_exact:
                                    selected_cols = ['W', 'X']
                                elif is_broad:
                                    selected_cols = ['AA', 'AB']
                            elif matched_category in ['case', 'åŒ…']:
                                if is_exact:
                                    selected_cols = ['Y', 'Z']
                                elif is_broad:
                                    selected_cols = ['AC', 'AD']
                            
                            # Collect data, track sources for duplicates
                            neg_data_sources = {
                                'å¦å®šç²¾å‡†åŒ¹é…': defaultdict(list),  # kw -> [col_keys]
                                'å¦å®šè¯ç»„': defaultdict(list)
                            }
                            for col_key in selected_cols:
                                if col_indices.get(col_key) is not None:
                                    col_idx = col_indices[col_key]
                                    col_data = [str(kw).strip() for kw in df_survey.iloc[:, col_idx].dropna() if str(kw).strip()]
                                    col_data = list(dict.fromkeys(col_data))  # column dedup
                                    m_type = 'å¦å®šç²¾å‡†åŒ¹é…' if col_key in ['W', 'AA', 'Y', 'AC'] else 'å¦å®šè¯ç»„'
                                    for kw in col_data:
                                        neg_data_sources[m_type][kw].append(col_key)
                            
                            # Check duplicates: kw with multiple sources
                            duplicates_detected = False
                            for m_type, kw_sources in neg_data_sources.items():
                                for kw, sources in kw_sources.items():
                                    if len(sources) > 1:
                                        duplicates_detected = True
                                        source_names = [col_names_dict.get(s, s) for s in sources]
                                        st.error(f"\n=== æ£€æµ‹åˆ°é‡å¤å¦å®šå…³é”®è¯ ===")
                                        st.error(f"æ´»åŠ¨: {campaign_name}")
                                        st.error(f"ç±»å‹: {m_type}")
                                        st.error(f"é‡å¤å…³é”®è¯: '{kw}'")
                                        st.error(f"æ¥æºåˆ—: {', '.join(source_names)}")
                                        st.error(f"åŸå› : è¯¥å…³é”®è¯åœ¨å¤šä¸ªå¦å®šåˆ—ä¸­å‡ºç°ï¼Œå¯¼è‡´ç”Ÿæˆé‡å¤è¡Œã€‚è¯·æ£€æŸ¥ survey æ–‡ä»¶çš„è¿™äº›åˆ—å¹¶æ¸…ç†é‡å¤å€¼ã€‚")
                                        st.error("æš‚åœç”Ÿæˆ header è¡¨ã€‚")
                                        os.unlink(input_file)
                                        return None  # Pause generation
                            
                            st.write("\n=== é‡å¤æ£€æµ‹å®Œæˆï¼ˆæ— é‡å¤ï¼‰===")
                            
                            # Generate rows: deduped kws
                            for m_type, kw_sources in neg_data_sources.items():
                                kws = list(kw_sources.keys())
                                if kws:
                                    st.write(f"  {m_type} å¦å®šå…³é”®è¯æ•°é‡: {len(kws)}")
                                for kw in kws:
                                    row_neg = [product_sp, 'å¦å®šå…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '', campaign_name, campaign_name, '', '', '', status, 
                                            '', '', '', '', kw, m_type, '', '', '', '']
                                    sp_rows.append(row_neg)
                    
                    # ASIN group: generate å•†å“å®šå‘ and å¦å®šå•†å“å®šå‘
                    if is_asin:
                        # å•†å“å®šå‘: exact column match to campaign_name
                        asin_targets = []
                        for col in df_survey.columns:
                            if str(col).strip() == str(campaign_name):
                                col_idx = df_survey.columns.get_loc(col)
                                if col_idx is not None:
                                    asin_targets = [str(asin).strip() for asin in df_survey.iloc[:, col_idx].dropna() if str(asin).strip()]
                                    asin_targets = list(dict.fromkeys(asin_targets))
                                    st.write(f"  å•†å“å®šå‘ ASIN æ•°é‡: {len(asin_targets)} (ç¤ºä¾‹: {asin_targets[:2] if asin_targets else 'æ— '})")
                                    break
                            
                        if asin_targets:
                            for asin in asin_targets:
                                row_product_target = [product_sp, 'å•†å“å®šå‘', operation, campaign_name, campaign_name, '', '', '', '', campaign_name, campaign_name, '', '', '', status, 
                                                    '', '', '', cpc, '', '', '', '', '', f'asin="{asin}"']
                                sp_rows.append(row_product_target)
                            
                        # å¦å®šå•†å“å®šå‘: from global neg_asin and neg_brand
                        for neg in neg_asin:
                            row_neg_product = [product_sp, 'å¦å®šå•†å“å®šå‘', operation, campaign_name, campaign_name, '', '', '', '', campaign_name, campaign_name, '', '', '', status, 
                                            '', '', '', '', '', '', '', '', '', f'asin="{neg}"']
                            sp_rows.append(row_neg_product)
                        
                        # æ¡ä»¶ç¦ç”¨: å¦å“ç‰Œå¾ªç¯
                        if False:  # ç¦ç”¨ SP å¦å“ç‰Œç”Ÿæˆ (æ”¹ä¸º True æ¢å¤)
                            for negb in neg_brand:
                                row_neg_brand = [product_sp, 'å¦å®šå•†å“å®šå‘', operation, campaign_name, campaign_name, '', '', '', '', campaign_name, campaign_name, '', '', '', status, 
                                                '', '', '', '', '', '', '', '', '', f'brand="{negb}"']
                                sp_rows.append(row_neg_brand)
                    
                    # æ–°å¢/ä¿®å¤ï¼šç«ä»·è°ƒæ•´å±‚çº§ï¼ˆä»…SPï¼Œä¸ºæ¯ä¸ªæ´»åŠ¨ç”Ÿæˆ1è¡Œï¼Œå¦‚æœæ¡ä»¶æ»¡è¶³ï¼‰- ç§»åˆ°if is_asinå¤–
                    row_bid_adjust = None  # é˜²æŠ¤ï¼šåˆå§‹åŒ–ä¸ºç©ºï¼Œé¿å…UnboundLocalError
                    ad_position = activity.get('ad_position', '').strip()
                    percentage = activity.get('percentage', '').strip()
                    if ad_position and percentage:  # åªæœ‰ä¸¤è€…éƒ½æœ‰å€¼æ‰ç”Ÿæˆ
                        st.write(f"  ç”Ÿæˆç«ä»·è°ƒæ•´è¡Œ (æ´»åŠ¨: {campaign_name}, å¹¿å‘Šä½: {ad_position}, ç™¾åˆ†æ¯”: {percentage})")
                        row_bid_adjust = [
                            product_sp, 'ç«ä»·è°ƒæ•´', operation,
                            campaign_name, '', '', '', '', '',
                            campaign_name, campaign_name, '', '',
                            'æ‰‹åŠ¨', status,
                            '', '', '', '', '', '',
                            'åŠ¨æ€ç«ä»· - ä»…é™ä½',
                            ad_position, percentage, ''
                        ]
                        sp_rows.append(row_bid_adjust)
                    else:
                        st.write(f"  è·³è¿‡ç«ä»·è°ƒæ•´è¡Œ (æ´»åŠ¨: {campaign_name})ï¼šå¹¿å‘Šä½æˆ–ç™¾åˆ†æ¯”ä¸ºç©º")
                
                else:
                    # Original Brand (SB/SBV) generation logic - with regional keyword rules
                    cpc = float(activity['cpc']) if activity['cpc'] != '' else default_bid
                    brand_budget = float(activity['budget']) if activity['budget'] != '' else 12
                    asins_str = activity.get('asins', '')
                    video_asset = activity.get('video_asset', '')  # æ–°å¢ï¼šä» activity è·å–
                    custom_image = activity.get('custom_image', '')  # æ–°å¢ï¼šä» activity è·å–
                    landing_url = global_settings.get('landing_url', '')
                    landing_type = activity.get('landing_type', '')
                    brand_name = global_settings.get('brand_name', '')
                    creative_title = global_settings.get('creative_title', '')
                    
                    # ç›´æ¥ä» activity å­—å…¸ä¸­è·å–ä¹‹å‰ä¿å­˜å¥½çš„ logo_asset
                    logo_asset = activity.get('logo_asset', '')
                    
                    campaign_name_normalized = str(campaign_name).lower()
                    
                    # Detect category and match type
                    matched_category = None
                    for cat in keyword_categories:
                        if cat in campaign_name_normalized:
                            matched_category = cat
                            break
                    
                    is_exact = any(x in campaign_name_normalized for x in ['ç²¾å‡†', 'exact'])
                    is_broad = any(x in campaign_name_normalized for x in ['å¹¿æ³›', 'broad'])
                    is_asin = any(x in campaign_name_normalized for x in ['asin'])  # è¦†ç›–èµ‹å€¼
                    match_type = 'ç²¾å‡†' if is_exact else 'å¹¿æ³›' if is_broad else 'ç²¾å‡†'
                    
                    # Row1: å¹¿å‘Šæ´»åŠ¨
                    row1 = [product_brand, 'å¹¿å‘Šæ´»åŠ¨', operation, campaign_name, '', '', campaign_name, '', '', status, 
                            global_settings.get('entity_id', ''), global_settings.get('budget_type', 'æ¯æ—¥'), brand_budget, 'åœ¨äºšé©¬é€Šä¸Šå‡ºå”®', '', '', '', '', '', '', '', '', '', '', '', '', '', '']
                    brand_rows.append(row1)
                    
                    # Row2: å¹¿å‘Šç»„
                    row2 = [product_brand, 'å¹¿å‘Šç»„', operation, campaign_name, campaign_name, '', campaign_name, campaign_name, '', status, 
                            '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']
                    brand_rows.append(row2)
                    
                    # Row3: å¹¿å‘Šå®ä½“å±‚çº§ï¼ˆå“ç‰Œè§†é¢‘å¹¿å‘Š / å•†å“é›†å¹¿å‘Š / è§†é¢‘å¹¿å‘Šï¼‰ - æŒ‰ä¸»é¢˜åˆ†å¼€å¤„ç†ï¼Œé¿å…å…±ç”¨é€»è¾‘
                    if 'SBVè½åœ°é¡µï¼šå“ç‰Œæ——èˆ°åº—' in target_theme:
                        # å“ç‰Œæ——èˆ°åº—è§†é¢‘å¹¿å‘Š
                        row3 = [product_brand, 'å“ç‰Œè§†é¢‘å¹¿å‘Š', operation,
                                campaign_name, campaign_name, campaign_name, '', '', campaign_name, status,
                                '', '', '', '', '', '', '', '',
                                landing_url, landing_type, brand_name, 'False', logo_asset, creative_title,
                                asins_str, video_asset, custom_image, '']
                        brand_rows.append(row3)

                    elif 'SBVè½åœ°é¡µï¼šå•†å“è¯¦æƒ…é¡µ' in target_theme:
                        row3 = [
                            product_brand, 'è§†é¢‘å¹¿å‘Š', operation,
                            campaign_name, campaign_name, campaign_name, '', '', campaign_name, status,
                            '', '', '', '', '', '', '', '',
                            '', landing_type or '', '', 'False',
                            '', '',
                            asins_str, video_asset, '', ''
                        ]
                        brand_rows.append(row3)

                    elif 'SBè½åœ°é¡µï¼šå•†å“é›†' in target_theme:
                        # 1. é»˜è®¤è®¾ç½®ï¼ˆå¸¸è§„è§„åˆ™ï¼‰ 
                        final_landing_url = landing_url
                        final_creative_asin = asins_str
                        final_landing_asin = ''

                        # 2. åº”ç”¨ä½ çš„æ–°è§„åˆ™ï¼šå¦‚æœæ˜¯â€œå•†å“åˆ—è¡¨â€ 
                        if landing_type == 'å•†å“åˆ—è¡¨':
                            final_landing_url = ''      # è½åœ°é¡µ URL ä¸ºç©º
                            final_creative_asin = ''   # åˆ›æ„ç´ æ ASIN ä¸ºç©º
                            final_landing_asin = asins_str  # å°†åŸæ¥çš„ ASIN å¡«åˆ°â€œè½åœ°é¡µ ASINâ€åˆ—
                        
                        # 3. ç”Ÿæˆç¬¬ 28 åˆ—æ•°æ®è¡Œ 
                        row3 = [
                            product_brand, 'å•†å“é›†å¹¿å‘Š', operation,
                            campaign_name, campaign_name, campaign_name, '', '', campaign_name, status,
                            '', '', '', '', '', '', '', '',
                            final_landing_url,     # å¯¹åº”ç¬¬19åˆ—ï¼šè½åœ°é¡µ URL
                            landing_type,          # å¯¹åº”ç¬¬20åˆ—ï¼šè½åœ°é¡µç±»å‹
                            brand_name,            # å¯¹åº”ç¬¬21åˆ—ï¼šå“ç‰Œåç§°
                            'False',               # å¯¹åº”ç¬¬22åˆ—ï¼šåŒæ„ç¿»è¯‘
                            logo_asset,            # å¯¹åº”ç¬¬23åˆ—ï¼šå“ç‰Œå¾½æ ‡ç´ æç¼–å·
                            creative_title,        # å¯¹åº”ç¬¬24åˆ—ï¼šåˆ›æ„ç´ ææ ‡é¢˜
                            final_creative_asin,   # å¯¹åº”ç¬¬25åˆ—ï¼šåˆ›æ„ç´ æ ASIN
                            video_asset,           # å¯¹åº”[cite: 5, 6]ï¼šè§†é¢‘ç´ æç¼–å·
                            custom_image,          # å¯¹åº”[cite: 7]ï¼šè‡ªå®šä¹‰å›¾ç‰‡
                            final_landing_asin     # å¯¹åº”ç¬¬28åˆ—ï¼šè½åœ°é¡µ ASIN (æ–°è§„åˆ™æ ¸å¿ƒ)
                        ]
                        brand_rows.append(row3)
                    
                    else:
                        st.warning(f"æœªè¯†åˆ«çš„ Brand ä¸»é¢˜ï¼š{target_theme}ï¼Œè·³è¿‡ç”Ÿæˆå¹¿å‘Šå®ä½“è¡Œ")
                    
                    # Keywords: dynamic column selection based on regional rules (SB/SBV)
                    if not is_asin:
                        keywords = []
                        keyword_col_idx = None
                        col_name = None  # For logging
                        
                        if match_type == 'ç²¾å‡†':
                            # All regions: original precise rules
                            if matched_category in ['suzhu', 'å®¿ä¸»', 'host']:
                                col_name = 'suzhu/å®¿ä¸»/host-ç²¾å‡†è¯'  # Låˆ—ï¼Œæ— ç©ºæ ¼
                            elif matched_category in ['case', 'åŒ…']:
                                col_name = 'case/åŒ…-ç²¾å‡†è¯'  # Oåˆ—
                        elif match_type == 'å¹¿æ³›':
                            # SB/SBV: regional rules - suzhu â†’ N, case â†’ Q
                            if matched_category in ['suzhu', 'å®¿ä¸»', 'host']:
                                col_name = 'suzhu/å®¿ä¸»/host-å¹¿æ³›è¯å¸¦åŠ å·'  # Nåˆ—ï¼Œæ— ç©ºæ ¼
                            elif matched_category in ['case', 'åŒ…']:
                                col_name = 'case/åŒ…-å¹¿æ³›è¯å¸¦åŠ å·'  # Qåˆ—
                        
                        if col_name and keyword_col_idx is None:  # Only if not already set
                            try:
                                keyword_col_idx = df_survey.columns.get_loc(col_name)
                            except KeyError:
                                st.warning(f"åˆ— '{col_name}' æœªæ‰¾åˆ°ï¼Œfallbackåˆ°ç¡¬ç¼–ç ")
                                # Fallback: regional indices for SB/SBV
                                if 'ç²¾å‡†' in match_type and matched_category in ['suzhu', 'å®¿ä¸»', 'host']:
                                    keyword_col_idx = 11  # L
                                elif 'ç²¾å‡†' in match_type and matched_category in ['case', 'åŒ…']:
                                    keyword_col_idx = 14  # O
                                elif 'å¹¿æ³›' in match_type and matched_category in ['suzhu', 'å®¿ä¸»', 'host']:
                                    keyword_col_idx = 13  # N
                                elif 'å¹¿æ³›' in match_type and matched_category in ['case', 'åŒ…']:
                                    keyword_col_idx = 16  # Q
                        
                        if keyword_col_idx is not None and keyword_col_idx < len(df_survey.columns):
                            col_data = [str(kw).strip() for kw in df_survey.iloc[:, keyword_col_idx].dropna() if str(kw).strip()]
                            keywords = list(dict.fromkeys(col_data))
                            col_name = str(df_survey.columns[keyword_col_idx]) if col_name is None else col_name
                            st.write(f"  åŒ¹é…çš„åˆ—: {col_name} (idx={keyword_col_idx})")
                            st.write(f"  å…³é”®è¯æ•°é‡: {len(keywords)} (ç¤ºä¾‹: {keywords[:2] if keywords else 'æ— '})")
                        else:
                            keywords = []
                            st.warning(f"  æ— åŒ¹é…åˆ— for {matched_category} {match_type} in {target_theme}")
                
                        if keywords:
                            for kw in keywords:
                                row_keyword = [product_brand, 'å…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '', status, 
                                            '', '', '', '', cpc, kw, match_type, '', '', '', '', '', '', '', '', '', '', '']
                                brand_rows.append(row_keyword)
                        else:
                            st.warning(f"  æ— å…³é”®è¯æ•°æ®ï¼Œè·³è¿‡ç”Ÿæˆå…³é”®è¯å±‚çº§ (æ´»åŠ¨: {campaign_name})")
                        
                        # Negative keywords: dynamic like test SB.py, with specific column selection
                        if matched_category:
                            # Select columns based on category and type
                            selected_cols = []
                            if matched_category in ['suzhu', 'å®¿ä¸»', 'host']:
                                if is_exact:
                                    selected_cols = ['W', 'X']
                                elif is_broad:
                                    selected_cols = ['AA', 'AB']
                            elif matched_category in ['case', 'åŒ…']:
                                if is_exact:
                                    selected_cols = ['Y', 'Z']
                                elif is_broad:
                                    selected_cols = ['AC', 'AD']
                            
                            # Collect data, track sources for duplicates
                            neg_data_sources = {
                                'å¦å®šç²¾å‡†åŒ¹é…': defaultdict(list),  # kw -> [col_keys]
                                'å¦å®šè¯ç»„': defaultdict(list)
                            }
                            for col_key in selected_cols:
                                if col_indices.get(col_key) is not None:
                                    col_idx = col_indices[col_key]
                                    col_data = [str(kw).strip() for kw in df_survey.iloc[:, col_idx].dropna() if str(kw).strip()]
                                    col_data = list(dict.fromkeys(col_data))  # column dedup
                                    m_type = 'å¦å®šç²¾å‡†åŒ¹é…' if col_key in ['W', 'AA', 'Y', 'AC'] else 'å¦å®šè¯ç»„'
                                    for kw in col_data:
                                        neg_data_sources[m_type][kw].append(col_key)
                            
                            # Check duplicates: kw with multiple sources
                            duplicates_detected = False
                            for m_type, kw_sources in neg_data_sources.items():
                                for kw, sources in kw_sources.items():
                                    if len(sources) > 1:
                                        duplicates_detected = True
                                        source_names = [col_names_dict.get(s, s) for s in sources]
                                        st.error(f"\n=== æ£€æµ‹åˆ°é‡å¤å¦å®šå…³é”®è¯ ===")
                                        st.error(f"æ´»åŠ¨: {campaign_name}")
                                        st.error(f"ç±»å‹: {m_type}")
                                        st.error(f"é‡å¤å…³é”®è¯: '{kw}'")
                                        st.error(f"æ¥æºåˆ—: {', '.join(source_names)}")
                                        st.error(f"åŸå› : è¯¥å…³é”®è¯åœ¨å¤šä¸ªå¦å®šåˆ—ä¸­å‡ºç°ï¼Œå¯¼è‡´ç”Ÿæˆé‡å¤è¡Œã€‚è¯·æ£€æŸ¥ survey æ–‡ä»¶çš„è¿™äº›åˆ—å¹¶æ¸…ç†é‡å¤å€¼ã€‚")
                                        st.error("æš‚åœç”Ÿæˆ header è¡¨ã€‚")
                                        os.unlink(input_file)
                                        return None  # Pause generation
                            
                            st.write("\n=== é‡å¤æ£€æµ‹å®Œæˆï¼ˆæ— é‡å¤ï¼‰===")
                            
                            # Generate rows: deduped kws
                            for m_type, kw_sources in neg_data_sources.items():
                                kws = list(kw_sources.keys())
                                if kws:
                                    st.write(f"  {m_type} å¦å®šå…³é”®è¯æ•°é‡: {len(kws)}")
                                for kw in kws:
                                    row_neg = [product_brand, 'å¦å®šå…³é”®è¯', operation, campaign_name, campaign_name, '', '', '', '', status, 
                                            '', '', '', '', '', kw, m_type, '', '', '', '', '', '', '', '', '', '', '']
                                    brand_rows.append(row_neg)
                    
                    # ASIN group: generate å•†å“å®šå‘ and å¦å®šå•†å“å®šå‘
                    if is_asin:
                        # å•†å“å®šå‘: exact column match to campaign_name
                        asin_targets = []
                        for col in df_survey.columns:
                            if str(col).strip() == str(campaign_name):
                                col_idx = df_survey.columns.get_loc(col)
                                if col_idx is not None:
                                    asin_targets = [str(asin).strip() for asin in df_survey.iloc[:, col_idx].dropna() if str(asin).strip()]
                                    asin_targets = list(dict.fromkeys(asin_targets))
                                    st.write(f"  å•†å“å®šå‘ ASIN æ•°é‡: {len(asin_targets)} (ç¤ºä¾‹: {asin_targets[:2] if asin_targets else 'æ— '})")
                                    break
                        
                        if asin_targets:
                            for asin in asin_targets:
                                row_product_target = [product_brand, 'å•†å“å®šå‘', operation, campaign_name, campaign_name, '', '', campaign_name, '', status, 
                                                    '', '', '', '', cpc, '', '', f'asin="{asin}"', '', '', '', '', '', '', '', '', '', '']
                                brand_rows.append(row_product_target)
                        
                        # å¦å®šå•†å“å®šå‘: from global neg_asin and neg_brand
                        for neg in neg_asin:
                            row_neg_product = [product_brand, 'å¦å®šå•†å“å®šå‘', operation, campaign_name, campaign_name, '', '', campaign_name, '', status, 
                                            '', '', '', '', '', '', '', f'asin="{neg}"', '', '', '', '', '', '', '', '', '', '']
                            brand_rows.append(row_neg_product)
                        
                        for negb in neg_brand:
                            row_neg_brand = [product_brand, 'å¦å®šå•†å“å®šå‘', operation, campaign_name, campaign_name, '', '', campaign_name, '', status, 
                                            '', '', '', '', '', '', '', f'brand="{negb}"', '', '', '', '', '', '', '', '', '', '']
                            brand_rows.append(row_neg_brand)
        
        # ======== ã€ä¿®æ”¹ 4 æ›´æ–°ç‰ˆã€‘æœ€ç»ˆé”™è¯¯æ‹¦æˆª ========
        if validation_errors:
            # ä½¿ç”¨ with error_area ç¡®ä¿è¿™ä¸€å †é”™è¯¯éƒ½æ˜¾ç¤ºåœ¨å¤–é¢
            with error_area:
                st.error("ğŸš« æ£€æµ‹åˆ° Excel æ¨¡ç‰ˆå¡«å†™ä¸å®Œæ•´ï¼Œå·²åœæ­¢ç”Ÿæˆï¼è¯·ä¿®å¤ä»¥ä¸‹é—®é¢˜ï¼š")
                for err in validation_errors:
                    st.error(err) # è¿™é‡Œæ¯ä¸€æ¡é”™è¯¯éƒ½ä¼šåˆ—åœ¨æœ€æ˜¾çœ¼çš„åœ°æ–¹
            
            os.unlink(input_file)
            return None
        # =============================================
        
        # Create DFs
        df_brand = pd.DataFrame(brand_rows, columns=output_columns_brand) if brand_rows else pd.DataFrame(columns=output_columns_brand)
        df_sp = pd.DataFrame(sp_rows, columns=output_columns_sp) if sp_rows else pd.DataFrame(columns=output_columns_sp)
        df_brand = df_brand.fillna('')
        df_sp = df_sp.fillna('')
        
        # Save to BytesIO for download - Multi-sheet
        output_buffer = io.BytesIO()
        with pd.ExcelWriter(output_buffer, engine='openpyxl') as writer:
            if not df_brand.empty:
                df_brand.to_excel(writer, index=False, sheet_name='å“ç‰Œå¹¿å‘Š')
            if not df_sp.empty:
                df_sp.to_excel(writer, index=False, sheet_name='SP-å•†å“æ¨å¹¿')
        output_buffer.seek(0)
        
    st.success(f"ç”Ÿæˆå®Œæˆï¼å“ç‰Œè¡Œæ•°ï¼š{len(brand_rows)}, SPè¡Œæ•°ï¼š{len(sp_rows)}")
        
    # Cleanup temp file
    os.unlink(input_file)
        
    return output_buffer

# Generate Button
if uploaded_file is not None:
    if st.button("ç”Ÿæˆ Header æ–‡ä»¶"):
        with st.spinner("æ­£åœ¨å¤„ç†æ–‡ä»¶..."):
            output_buffer = generate_header_for_sbv_brand_store(uploaded_file.read())
            if output_buffer is not None:
                # Generate filename with current time (precise to minute)
                now = datetime.now()
                timestamp = now.strftime("%Y-%m-%d %H:%M")
                filename = f"header-{timestamp}.xlsx"
                
                st.download_button(
                    label="ä¸‹è½½ç”Ÿæˆçš„ Header æ–‡ä»¶",
                    data=output_buffer.getvalue(),
                    file_name=filename,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
else:
    st.info("è¯·ä¸Šä¼  Excel æ–‡ä»¶ä»¥å¼€å§‹ç”Ÿæˆã€‚")